{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Mask_RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-output": true,
        "_kg_hide-input": true,
        "id": "y18mjN6lMibS",
        "colab_type": "code",
        "outputId": "aa6c6861-7327-4b17-9c7b-aba11ec41b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0-FcwbAZ7NR",
        "colab_type": "code",
        "outputId": "9ef3f386-6126-4504-c9a9-ae9f171c33f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mgdrive\u001b[0m/  mask_rcnn_coco.h5  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLhZZE8MgiWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip uninstall -y kaggle\n",
        "# !pip install --upgrade pip\n",
        "# !pip install kaggle==1.5.6\n",
        "# !kaggle -v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOqQnnOwZwg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# files.upload() #this will prompt you to upload the kaggle.json\n",
        "\n",
        "# !mkdir -p \"/root/.kaggle\"\n",
        "# !cp kaggle.json \"/root/.kaggle/\"\n",
        "# !ls \"/root/.kaggle\"\n",
        "# # we need to set permissions \n",
        "# !chmod 600 \"/root/.kaggle/kaggle.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "All3uvhDasu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !kaggle kernels list --user 'utopi4' --sort-by dateRun"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWlV_fxwde5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# os.chdir('/content/gdrive/My Drive/Kaggle')#change dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy3e5tpUeggm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzO9d3ZMeleL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !kaggle kernels pull 'utopi4/mask-rcnn-detailed-starter-code' -m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55TwZO8hMkv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# library imports\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import random as rn\n",
        "import cv2 as cv \n",
        "import os\n",
        "import glob\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# neural network wizardry\n",
        "# import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "# tf.disable_v2_behavior()\n",
        "# visuals\n",
        "from matplotlib import pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed()\n",
        "# tf.random.set_seed(RANDOM_SEED)\n",
        "tf.set_random_seed(RANDOM_SEED)\n",
        "rn.seed(RANDOM_SEED)\n",
        "\n",
        "# paths\n",
        "# img_train_folder = Path('/kaggle/input/severstal-steel-defect-detection/train_images/')\n",
        "# img_test_folder = Path('/kaggle/input/severstal-steel-defect-detection/test_images/')\n",
        "img_train_folder = Path('/content/gdrive/My Drive/Kaggle/severstal-steel-defect-detection/train_images')\n",
        "img_test_folder = Path('/content/gdrive/My Drive/Kaggle/severstal-steel-defect-detection/test_images/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6DIqOvAo5VI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_path = os.path.join(img_test_folder,'*g')\n",
        "# files = glob.glob(data_path)\n",
        "# data = []\n",
        "# i = 0\n",
        "# for f1 in files:\n",
        "#     img = cv.imread(f1)\n",
        "#     data.append(img)\n",
        "#     i = i + 1\n",
        "#     if (i==1):\n",
        "#       break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf-l30tOqhed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(data[0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyA2MXPfMibZ",
        "colab_type": "text"
      },
      "source": [
        "# Foreword\n",
        "The main goal of this notebook is to make the ideas presented easy to understand. I try my best to be as verbose as possible, but if you have remaining questions, I'll happily answer them in the comments.\n",
        "\n",
        "Carefully illustrating ideas takes a lot more time than just writing up code, so upvotes are much appreciated.\n",
        "\n",
        "# Kernel Structure\n",
        "* [Competition Information](#1)\n",
        "<br><span style=\"font-size:10px\">We discuss the format required from us by the competition, as well as the loss function of choice and the type of encoding used.</span>\n",
        "* [Exploratory Data Analysis & Baseline](#2)\n",
        "<br><span style=\"font-size:10px\">There is a class imbalance that will have to be dealt with. We also show accuracy is the wrong metric due to the majority class (no defects) being the majority class.</span>\n",
        "* [Input/Output Data Shapes](#3)\n",
        "<br><span style=\"font-size:10px\">Understanding the dimensions of the in- and output that the neural network will be expecting.</span>\n",
        "* [A First Look: Visualising the Masks](#4)\n",
        "<br><span style=\"font-size:10px\">We define some utility functions and show some instances of defects.</span>\n",
        "* [Formulating the Problem: Semantic Segmentation](#5)\n",
        "<br><span style=\"font-size:10px\">We define what task is expected of us.</span>\n",
        "* [Setting up our ML model: Mask R-CNN](#6)\n",
        "<br><span style=\"font-size:10px\">Cloning and configuring Matterport's implementation of Mask RCNN.</span>\n",
        "* [Training](#7)\n",
        "<br><span style=\"font-size:10px\">Currently configured to run a single epoch. This should allow you to get started!</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnkI7VmtMiba",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"1\"></a> <br>\n",
        "# Competition Information\n",
        "\n",
        "## Prediction Output Format\n",
        "From the competition's [data](https://www.kaggle.com/c/severstal-steel-defect-detection/data) page:\n",
        "> Each image may have no defects, a defect of a single class, or defects of multiple classes. For each image you must segment defects of each class ```(ClassId = [1, 2, 3, 4])```.\n",
        "\n",
        "The submission format requires us to make the classifications for each respective class on a separate row, adding the *_class* to the imageId:\n",
        "![format](https://i.imgur.com/uEeoOQg.png)\n",
        "\n",
        "## Loss Function\n",
        "\n",
        "### Dice Coefficient\n",
        "From the [evaluation](https://www.kaggle.com/c/severstal-steel-defect-detection/overview/evaluation) page:\n",
        "\n",
        "> This competition is evaluated on the mean Dice coefficient. The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth. The formula is given by:\n",
        ">\n",
        ">$$Dice(X,Y) = \\frac{2∗|X∩Y|}{|X|+|Y|}$$\n",
        ">\n",
        ">\n",
        ">where X is the predicted set of pixels and Y is the ground truth. The Dice coefficient is defined to be 1 when both X and Y are empty. The leaderboard score is the mean of the Dice coefficients for each ```<ImageId, ClassId>``` pair in the test set.\n",
        "\n",
        "Or if you prefer a visual illustration:\n",
        "![dice_viz](https://i.imgur.com/zl2W0xQ.png)\n",
        "\n",
        "\n",
        "To get a better understanding, let's demonstrate with a quick toy example as we write the function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0AD5nvmUMiba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imagine a 3*3 image with a diagional line across\n",
        "X = np.eye(3,3, dtype=np.uint8)\n",
        "Y = np.eye(3,3, dtype=np.uint8)\n",
        "\n",
        "# we change one pixel\n",
        "X[1,1] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "fyC9zxgmMibe",
        "colab_type": "code",
        "outputId": "e0721311-358e-4cb8-ad82-a374e17aad52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "print(X)\n",
        "print('')\n",
        "print(Y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]]\n",
            "\n",
            "[[1 0 0]\n",
            " [0 1 0]\n",
            " [0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_5WlnThmMibj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coefficient(X, y):\n",
        "    \n",
        "    # convert the pixel/mask matrix to a one-dimensional series\n",
        "    predicted = X.flatten()\n",
        "    truth = y.flatten()\n",
        "    \n",
        "    # our masks will consist of ones and zeros\n",
        "    # summing the result of their product gives us the cross section\n",
        "    overlap = np.sum(predicted * truth)\n",
        "    total_surface_area = np.sum(predicted + truth)\n",
        "    \n",
        "    # passing our calculated values to the formula\n",
        "    return 2 * overlap / total_surface_area"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "J2whZ0hOMibm",
        "colab_type": "code",
        "outputId": "d636ee9c-ae66-48f0-d5b5-d6c2450b3fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(f'The dice coefficient for 1 wrongly labeled pixel in a 3*3 image is: {dice_coefficient(X, Y)}')\n",
        "print('(2 * 2 overlapping \"1\" pixels / 5 total \"1\" surface area)')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dice coefficient for 1 wrongly labeled pixel in a 3*3 image is: 0.8\n",
            "(2 * 2 overlapping \"1\" pixels / 5 total \"1\" surface area)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeOghXakMibr",
        "colab_type": "text"
      },
      "source": [
        "### *Mean* Dice Coefficient\n",
        "The dataset's original format (one row per *imageId:classId* pair) points at the fact that we will have to run this dice coefficient function over every layer in our mask and take the average. If we train multiple images at a time, we will have to take the average across a batch. More about this in the **Data Shapes** chapter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVN9TF0wMibr",
        "colab_type": "text"
      },
      "source": [
        "## Run-Length Encoding\n",
        "> In order to reduce the submission file size, our metric uses run-length encoding on the pixel values. Instead of submitting an exhaustive list of indices for your segmentation, you will submit **pairs of values** that contain a **start position and a run length**. E.g. '1 3' implies starting at pixel 1 and running a total of 3 pixels (1,2,3).\n",
        ">\n",
        ">The competition format requires a **space delimited list of pairs**. For example, '1 3 10 5' implies pixels 1,2,3,10,11,12,13,14 are to be included in the mask. The metric checks that the pairs are **sorted, positive, and the decoded pixel values are not duplicated**. The pixels are numbered from top to bottom, then left to right: 1 is pixel (1,1), 2 is pixel (2,1), etc.\n",
        "\n",
        "So, if we were to encode something like our example above, we would have to write it as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "H2eZMrI5Mibs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a more elaborate version of kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
        "# note that we will transpose the incoming array outside of the function, \n",
        "# as I find this a clearer illustration\n",
        "\n",
        "def mask_to_rle(mask):\n",
        "    \"\"\"\n",
        "    params:  mask - numpy array\n",
        "    returns: run-length encoding string (pairs of start & length of encoding)\n",
        "    \"\"\"\n",
        "    \n",
        "    # turn a n-dimensional array into a 1-dimensional series of pixels\n",
        "    # for example:\n",
        "    #     [[1. 1. 0.]\n",
        "    #      [0. 0. 0.]   --> [1. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
        "    #      [1. 0. 0.]]\n",
        "    flat = mask.flatten()\n",
        "    \n",
        "    # we find consecutive sequences by overlaying the mask\n",
        "    # on a version of itself that is displaced by 1 pixel\n",
        "    # for that, we add some padding before slicing\n",
        "    padded = np.concatenate([[0], flat, [0]])\n",
        "    \n",
        "    # this returns the indeces where the sliced arrays differ\n",
        "    runs = np.where(padded[1:] != padded[:-1])[0] \n",
        "    # indexes start at 0, pixel numbers start at 1\n",
        "    runs += 1\n",
        "\n",
        "    # every uneven element represents the start of a new sequence\n",
        "    # every even element is where the run comes to a stop\n",
        "    # subtract the former from the latter to get the length of the run\n",
        "    runs[1::2] -= runs[0::2]\n",
        " \n",
        "    # convert the array to a string\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "GzXhklkGMibw",
        "colab_type": "code",
        "outputId": "0869dccd-072c-43d9-c720-c0f64effb1e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rle_example = mask_to_rle(X)\n",
        "print(f'The run-length encoding for our example would be: \"{rle_example}\"')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The run-length encoding for our example would be: \"1 1 9 1\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1AL0IPDMMib0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rle_to_mask(lre, shape=(1600,256)):\n",
        "    '''\n",
        "    params:  rle   - run-length encoding string (pairs of start & length of encoding)\n",
        "             shape - (width,height) of numpy array to return \n",
        "    \n",
        "    returns: numpy array with dimensions of shape parameter\n",
        "    '''    \n",
        "    # the incoming string is space-delimited\n",
        "    runs = np.asarray([int(run) for run in lre.split(' ')])\n",
        "    \n",
        "    # we do the same operation with the even and uneven elements, but this time with addition\n",
        "    runs[1::2] += runs[0::2]\n",
        "    # pixel numbers start at 1, indexes start at 0\n",
        "    runs -= 1\n",
        "    \n",
        "    # extract the starting and ending indeces at even and uneven intervals, respectively\n",
        "    run_starts, run_ends = runs[0::2], runs[1::2]\n",
        "    \n",
        "    # build the mask\n",
        "    h, w = shape\n",
        "    mask = np.zeros(h*w, dtype=np.uint8)\n",
        "    for start, end in zip(run_starts, run_ends):\n",
        "        mask[start:end] = 1\n",
        "    \n",
        "    # transform the numpy array from flat to the original image shape\n",
        "    return mask.reshape(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "EfSFCIEfMib4",
        "colab_type": "code",
        "outputId": "7d168742-2fb7-4709-dc68-2154db61645e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(f'The mask reconstructed from the run-length encoding (\"{rle_example}\") \\\n",
        "for our example would be:\\n{rle_to_mask(rle_example, shape=(3,3))}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mask reconstructed from the run-length encoding (\"1 1 9 1\") for our example would be:\n",
            "[[1 0 0]\n",
            " [0 0 0]\n",
            " [0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5bSXbDHMib8",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"2\"></a> <br>\n",
        "# Exploratory Data Analysis\n",
        "\n",
        "## Class Imbalances\n",
        "A huge imbalance quickly becomes apparent when looking at the training set description:\n",
        "\n",
        "![class_imbalance](https://i.imgur.com/B4Dsxur.png)\n",
        "\n",
        "Only 7095 pictures will be of any use to us when training... (you wouldn't train a pedestrian detector on a dataset of empty streets, either).\n",
        "\n",
        "## Baseline\n",
        "If we'd train on the entire dataset, the risk is substantial that our model will simply learn the **majority class** (no defect, ever).\n",
        "Indeed, if we simply upload the sample submission, we have a score of:\n",
        "\n",
        "![baseline_code](https://i.imgur.com/zAxYg4g.png)\n",
        "![baseline_score](https://i.imgur.com/AXaygTV.png)\n",
        "\n",
        "This is the benchmark to beat. \n",
        "\n",
        "## Class Imbalances (continued)\n",
        "Let's see how often each class appears, as well as how the class distribution is inside images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zhfAv-AfMib8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reading in the training set\n",
        "data = pd.read_csv('/content/gdrive/My Drive/Kaggle/severstal-steel-defect-detection/train.csv')\n",
        "\n",
        "# isolating the file name and class\n",
        "data['ImageId'] = data.ImageId\n",
        "data['ClassId'] = data.ClassId\n",
        "# data['ImageId'], data['ClassId'] = data.ImageId_ClassId.str.split('_', n=1).str\n",
        "data['ClassId'] = data['ClassId'].astype(np.uint8)\n",
        "\n",
        "# storing a list of images without defects for later use and testing\n",
        "no_defects = data[data['EncodedPixels'].isna()] \\\n",
        "                [['ImageId']] \\\n",
        "                .drop_duplicates()\n",
        "\n",
        "# adding the columns so we can append (a sample of) the dataset if need be, later\n",
        "no_defects['EncodedPixels'] = ''\n",
        "no_defects['ClassId'] = np.empty((len(no_defects), 0)).tolist()\n",
        "no_defects['Distinct Defect Types'] = 0\n",
        "no_defects.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pYHoAe_2MicA",
        "colab_type": "code",
        "outputId": "ab2c1265-765b-430e-c213-eeef0948b806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# keep only the images with labels\n",
        "squashed = data.dropna(subset=['EncodedPixels'], axis='rows', inplace=True)\n",
        "\n",
        "# squash multiple rows per image into a list\n",
        "squashed = data[['ImageId', 'EncodedPixels', 'ClassId']] \\\n",
        "            .groupby('ImageId', as_index=False) \\\n",
        "            .agg(list) \\\n",
        "\n",
        "# count the amount of class labels per image\n",
        "squashed['Distinct Defect Types'] = squashed.ClassId.apply(lambda x: len(x))\n",
        "\n",
        "# display first ten to show new structure\n",
        "squashed.head(10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "      <th>ClassId</th>\n",
              "      <th>Distinct Defect Types</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002cc93b.jpg</td>\n",
              "      <td>[29102 12 29346 24 29602 24 29858 24 30114 24 ...</td>\n",
              "      <td>[1]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0007a71bf.jpg</td>\n",
              "      <td>[18661 28 18863 82 19091 110 19347 110 19603 1...</td>\n",
              "      <td>[3]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000a4bcdd.jpg</td>\n",
              "      <td>[37607 3 37858 8 38108 14 38359 20 38610 25 38...</td>\n",
              "      <td>[1]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000f6bf48.jpg</td>\n",
              "      <td>[131973 1 132228 4 132483 6 132738 8 132993 11...</td>\n",
              "      <td>[4]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0014fce06.jpg</td>\n",
              "      <td>[229501 11 229741 33 229981 55 230221 77 23046...</td>\n",
              "      <td>[3]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0025bde0c.jpg</td>\n",
              "      <td>[8458 14 8707 35 8963 48 9219 71 9475 88 9731 ...</td>\n",
              "      <td>[3, 4]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>002af848d.jpg</td>\n",
              "      <td>[290800 6 291055 13 291311 15 291566 18 291822...</td>\n",
              "      <td>[4]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>002fc4e19.jpg</td>\n",
              "      <td>[146021 3 146275 10 146529 40 146783 46 147038...</td>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0030401a5.jpg</td>\n",
              "      <td>[186833 1 187089 3 187344 6 187600 7 187855 10...</td>\n",
              "      <td>[4]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0046839bd.jpg</td>\n",
              "      <td>[152926 1 153180 4 153434 6 153689 8 153943 11...</td>\n",
              "      <td>[3]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ImageId  ... Distinct Defect Types\n",
              "0  0002cc93b.jpg  ...                     1\n",
              "1  0007a71bf.jpg  ...                     1\n",
              "2  000a4bcdd.jpg  ...                     1\n",
              "3  000f6bf48.jpg  ...                     1\n",
              "4  0014fce06.jpg  ...                     1\n",
              "5  0025bde0c.jpg  ...                     2\n",
              "6  002af848d.jpg  ...                     1\n",
              "7  002fc4e19.jpg  ...                     2\n",
              "8  0030401a5.jpg  ...                     1\n",
              "9  0046839bd.jpg  ...                     1\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "eVslPhIVMicE",
        "colab_type": "code",
        "outputId": "5b9bee32-d0ae-4293-d9e3-3a6ea930dd93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "print(f\"\"\"The training set now consists of {len(squashed):,} distinct images,\n",
        "for a total of {squashed[\"Distinct Defect Types\"].sum():,} labeled mask instances.\n",
        "\n",
        "Furthermore, we have kept a backup of {len(no_defects):,} images witout defects,\n",
        "in case our model starts producing a lot of false positives and needs more training\n",
        "on a background class.\"\"\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training set now consists of 6,666 distinct images,\n",
            "for a total of 7,095 labeled mask instances.\n",
            "\n",
            "Furthermore, we have kept a backup of 0 images witout defects,\n",
            "in case our model starts producing a lot of false positives and needs more training\n",
            "on a background class.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "eo1b9PDJMicH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" use a consistent color palette per label throughout the notebook \"\"\"\n",
        "import colorlover as cl\n",
        "\n",
        "# see: https://plot.ly/ipython-notebooks/color-scales/\n",
        "colors = cl.scales['4']['qual']['Set3']\n",
        "labels = np.array(range(1,5))\n",
        "\n",
        "# combining into a dictionary\n",
        "palette = dict(zip(labels, np.array(cl.to_numeric(colors))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "WrcVnQy4MicL",
        "colab_type": "code",
        "outputId": "8320dec5-0f3a-455a-bcf6-18af437b9ec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "# we want counts & frequency of the labels\n",
        "classes = data.groupby(by='ClassId', as_index=False) \\\n",
        "               .agg({'ImageId':'count'}) \\\n",
        "               .rename(columns={'ImageId':'Count'})\n",
        "\n",
        "classes['Frequency'] = round(classes.Count / classes.Count.sum() * 100, 2) \n",
        "classes['Frequency'] = classes['Frequency'].astype(str) + '%'\n",
        "\n",
        "# plotly for interactive graphs\n",
        "fig = go.Figure(\n",
        "    \n",
        "    data=go.Bar(\n",
        "        orientation='h',\n",
        "        x=classes.Count,\n",
        "        y=classes.ClassId,\n",
        "        hovertext=classes.Frequency,\n",
        "        text=classes.Count,\n",
        "        textposition='auto',\n",
        "        marker_color=colors),\n",
        "    \n",
        "    layout=go.Layout(\n",
        "        title='Defect Type: Count & Frequency',\n",
        "        showlegend=False,\n",
        "        xaxis=go.layout.XAxis(showticklabels=False),\n",
        "        yaxis=go.layout.YAxis(autorange='reversed'),\n",
        "        width=750, height=400\n",
        "    )\n",
        ")\n",
        "\n",
        "# display\n",
        "fig.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"085ae63c-c02a-4575-8424-6cc8ff5ce900\" class=\"plotly-graph-div\" style=\"height:400px; width:750px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"085ae63c-c02a-4575-8424-6cc8ff5ce900\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '085ae63c-c02a-4575-8424-6cc8ff5ce900',\n",
              "                        [{\"hovertext\": [\"12.64%\", \"3.48%\", \"72.59%\", \"11.29%\"], \"marker\": {\"color\": [\"rgb(141,211,199)\", \"rgb(255,255,179)\", \"rgb(190,186,218)\", \"rgb(251,128,114)\"]}, \"orientation\": \"h\", \"text\": [897.0, 247.0, 5150.0, 801.0], \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [897, 247, 5150, 801], \"y\": [1, 2, 3, 4]}],\n",
              "                        {\"height\": 400, \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Defect Type: Count & Frequency\"}, \"width\": 750, \"xaxis\": {\"showticklabels\": false}, \"yaxis\": {\"autorange\": \"reversed\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('085ae63c-c02a-4575-8424-6cc8ff5ce900');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MA6_SiLMicO",
        "colab_type": "text"
      },
      "source": [
        "An overwhelming amount of the observations is for class 3. Hopefully we can balance this out at least a little with some data augmentation later.\n",
        "\n",
        "Let's see what the distributions are if we consider all possible combinations, inccluding multi-class instances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "GNhRBm8gMicP",
        "colab_type": "code",
        "outputId": "5026fb2c-96ba-42a1-c498-d4a08495a1ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "# we want counts of the possible combinations of labels\n",
        "permutations = pd.DataFrame(data=squashed.ClassId.astype(str).value_counts())\n",
        "\n",
        "# and their frequency\n",
        "permutations['Frequency'] = round(permutations.ClassId / permutations.ClassId.sum() * 100, 2)\n",
        "permutations['Frequency'] = permutations['Frequency'].astype(str) + '%'\n",
        "\n",
        "# plotly for interactive graphs\n",
        "fig = go.Figure(\n",
        "    \n",
        "    data=go.Bar(\n",
        "        orientation='h',\n",
        "        x=permutations.ClassId,\n",
        "        y=permutations.index,\n",
        "        hovertext=permutations.Frequency,\n",
        "        text=permutations.ClassId,\n",
        "        textposition='auto'),\n",
        "    \n",
        "    layout=go.Layout(\n",
        "        title='Count of Distinct Defect Combinations in Images',\n",
        "        showlegend=False,\n",
        "        xaxis=go.layout.XAxis(showticklabels=False),\n",
        "        yaxis=go.layout.YAxis(autorange='reversed'),\n",
        "        width=750, height=500\n",
        "    )\n",
        ")\n",
        "\n",
        "# display\n",
        "fig.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"dfeb73ca-181e-4dae-bcec-3da64a7c7654\" class=\"plotly-graph-div\" style=\"height:500px; width:750px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"dfeb73ca-181e-4dae-bcec-3da64a7c7654\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'dfeb73ca-181e-4dae-bcec-3da64a7c7654',\n",
              "                        [{\"hovertext\": [\"71.39%\", \"11.54%\", \"7.74%\", \"4.26%\", \"2.93%\", \"1.37%\", \"0.53%\", \"0.21%\", \"0.03%\", \"0.02%\"], \"orientation\": \"h\", \"text\": [4759.0, 769.0, 516.0, 284.0, 195.0, 91.0, 35.0, 14.0, 2.0, 1.0], \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [4759, 769, 516, 284, 195, 91, 35, 14, 2, 1], \"y\": [\"[3]\", \"[1]\", \"[4]\", \"[3, 4]\", \"[2]\", \"[1, 3]\", \"[1, 2]\", \"[2, 3]\", \"[1, 2, 3]\", \"[2, 4]\"]}],\n",
              "                        {\"height\": 500, \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Count of Distinct Defect Combinations in Images\"}, \"width\": 750, \"xaxis\": {\"showticklabels\": false}, \"yaxis\": {\"autorange\": \"reversed\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('dfeb73ca-181e-4dae-bcec-3da64a7c7654');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNsJAuYvMicT",
        "colab_type": "text"
      },
      "source": [
        "It looks like combinations of two labels in a single image are reasonably frequent, too. In fact, 3 & 4 appear together more often than 2 does on its own!\n",
        "\n",
        "<a id=\"3\"></a> <br>\n",
        "# Data Shapes\n",
        "\n",
        "## Images\n",
        "The input shape will be an image we convert to a three-dimensional array with shape ```(256, 1600, 3)```, for height, width, and the three colour channels (RGB), respectively.\n",
        "\n",
        "## Labels\n",
        "Naturally, the masks will share the same width and height, but the third dimension will be as large as there are labels ```(256, 1600, 4)```, with each class occupying a different layer. Somewhat like this:\n",
        "![label shape](https://i.imgur.com/PePSemo.png)\n",
        "\n",
        "## Batch Size\n",
        "To leverage the parellel computation a GPU offers, we will feed the images and their labels to the algorithm in batches. Consequently, our array dimensions will be expanded to ```(batch size, 256, 1600, 3)``` and ```(batch size, 256, 1600, 4)```, respectively.\n",
        "\n",
        "If you remember our dice coefficient, we will have to calculate it for evey layer in every mask, and take the average over the entire batch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxcJIU1TMicT",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"4\"></a> <br>\n",
        "# Visualising the Masks\n",
        "Let's take a look at some examples of each class, and of some of the images containing multiple classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3JcyUD_oMicU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_mask(encodings, labels):\n",
        "    \"\"\" takes a pair of lists of encodings and labels, \n",
        "        and turns them into a 3d numpy array of shape (256, 1600, 4) \n",
        "    \"\"\"\n",
        "    \n",
        "    # initialise an empty numpy array \n",
        "    mask = np.zeros((256,1600,4), dtype=np.uint8)\n",
        "#     set_trace()\n",
        "    # building the masks\n",
        "    for rle, label in zip(encodings, labels):\n",
        "        \n",
        "        # classes are [1, 2, 3, 4], corresponding indeces are [0, 1, 2, 3]\n",
        "        index = label - 1\n",
        "        \n",
        "        # fit the mask into the correct layer\n",
        "        # note we need to transpose the matrix to account for \n",
        "        # numpy and openCV handling width and height in reverse order \n",
        "        mask[:,:,index] = rle_to_mask(rle).T\n",
        "#     set_trace()\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "j31E4xn-MicX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask_to_contours(image, mask_layer, color):\n",
        "    \"\"\" converts a mask to contours using OpenCV and draws it on the image\n",
        "    \"\"\"\n",
        "\n",
        "    # https://docs.opencv.org/4.1.0/d4/d73/tutorial_py_contours_begin.html\n",
        "    contours, hierarchy = cv.findContours(mask_layer, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
        "    image = cv.drawContours(image, contours, -1, color, 2)\n",
        "        \n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "G3zD4TxfMicb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualise_mask(file_name, mask):\n",
        "    \"\"\" open an image and draws clear masks, so we don't lose sight of the \n",
        "        interesting features hiding underneath \n",
        "    \"\"\"\n",
        "    \n",
        "    # reading in the image\n",
        "    image = cv.imread(f'{img_train_folder}/{file_name}')\n",
        "\n",
        "    # going through the 4 layers in the last dimension \n",
        "    # of our mask with shape (256, 1600, 4)\n",
        "    for index in range(mask.shape[-1]):\n",
        "        \n",
        "        # indeces are [0, 1, 2, 3], corresponding classes are [1, 2, 3, 4]\n",
        "        label = index + 1\n",
        "        \n",
        "        # add the contours, layer per layer \n",
        "        image = mask_to_contours(image, mask[:,:,index], color=palette[label])   \n",
        "        \n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_kg_hide-input": true,
        "id": "MHOcBJEWMicg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pdb import set_trace\n",
        "# # the images we want to see\n",
        "# conditions = [\n",
        "#     squashed['ClassId'].astype(str)=='[1]',\n",
        "#     squashed['ClassId'].astype(str)=='[2]',\n",
        "#     squashed['ClassId'].astype(str)=='[3]',\n",
        "#     squashed['ClassId'].astype(str)=='[4]',\n",
        "#     squashed['Distinct Defect Types']==2,\n",
        "#     squashed['Distinct Defect Types']==3\n",
        "# ]\n",
        "\n",
        "# # max 2 due to limited population of [squashed['Distinct Defect Types']==3]\n",
        "# # remove that condition if you wish to increase the sample size, \n",
        "# # or add replace=True to the .sample() method\n",
        "# sample_size = 2\n",
        "\n",
        "# # looping over the different combinations of labels \n",
        "# for condition in conditions:\n",
        "    \n",
        "#     # isolate from dataset and draw a sample\n",
        "#     sample = squashed[condition].sample(sample_size) \n",
        "# #     set_trace()\n",
        "#     # make a subplot+\n",
        "#     fig, axes = plt.subplots(sample_size, 1, figsize=(16, sample_size*3))\n",
        "#     fig.tight_layout()\n",
        "    \n",
        "#     # looping over sample\n",
        "#     for i, (index, row) in enumerate(sample.iterrows()):\n",
        "        \n",
        "#         # current ax\n",
        "#         ax = axes[i,]\n",
        "# #         set_trace()\n",
        "#         # build the mask\n",
        "#         mask = build_mask(encodings=row.EncodedPixels, labels=row.ClassId)\n",
        "\n",
        "#         # fetch the image and draw the contours\n",
        "#         image = visualise_mask(file_name=row.ImageId, mask=mask)\n",
        "        \n",
        "#         # display\n",
        "#         ax.set_title(f'{row.ImageId}: {row.ClassId}')\n",
        "#         ax.axis('off')\n",
        "#         ax.imshow(image);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VghXhD0bMick",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"5\"></a> <br>\n",
        "# Semantic Segmentation\n",
        "Below are some of the common tasks in the field of Machine Vision:\n",
        "![semantic_segmentation](https://miro.medium.com/max/1838/1*Tb3CvTONAA4IVL-HciJscw.jpeg)\n",
        "\n",
        "We are dealing with the problem of semantic segmentation: predicting a pixel-by-pixel mask of distinct classes.\n",
        "Check out Priya Dwivedi's [excellent blogpost](https://towardsdatascience.com/semantic-segmentation-popular-architectures-dff0a75f39d0) on the topic if you want to read more.\n",
        "\n",
        "<a id=\"6\"></a> <br>\n",
        "# Mask R-CNN\n",
        "Mask R-CNN falls under the category of meta-algorithms, rather than purely a neural network architecture. In fact, it builds on the faster R-CNN architecture, so you even have a choice of what neural net 'backbone' you want it to use.\n",
        "\n",
        "![maskrcnn-framework](https://miro.medium.com/max/1285/1*IWWOPIYLqqF9i_gXPmBk3g.png)\n",
        "\n",
        "\n",
        "The most important aspects of this algorithm are:\n",
        "* **FPN (feature pyramid network)** - A fully convolutional neural architecture designed to extract features.\n",
        "* **RPN (region proposal network)** - A lightweight neural network that scans over the FPN features to suggest ROI (regions of interest)\n",
        "* **ROIAlign** - a novel way to pass the object to the classifier an mask generator. Contrary to the ROIpool mechanism that was the standard, this one uses [bilinear interpolation](https://www.quora.com/How-does-ROTAlign-work-in-Mask-RCNN) to improve performance significantly.\n",
        "* **Classifier & Bounding Box Regressor**. \n",
        "* **Mask Generator** - A convolutional network that takes the regions selected by the ROI classifier and generates soft masks for them. \n",
        "\n",
        "Read more on [Matterport's official blog](https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46) <br>\n",
        "You can also check out the original paper's authors presenting the Mask R-CNN [on YouTube](https://youtu.be/g7z4mkfRjI4)\n",
        "\n",
        "## Importing\n",
        "For instructions on how to import models into a Kaggle kernel, check out the following Medium article: [Setting Up Mask-RCNN on Kaggle](https://medium.com/@umdfirecoml/setting-up-mask-rcnn-on-kaggle-34b656140b5e)\n",
        "\n",
        "2019/10/10: <br> \n",
        "This method currently produces an error message when committing. <br> \n",
        "```Output path '/Mask_RCNN/.git/logs/refs/remotes/origin/HEAD' contains too many nested subdirectories (max 6)```. <br> \n",
        "I resort to Simon Walker's method to get around this.\n",
        "\n",
        "2019/10/17: <br>\n",
        "A Keras update means the model now produces an error [documented in issue #1754](https://github.com/matterport/Mask_RCNN/issues/1754). <br>\n",
        "I therefore cloned the repo and applied a small fix. <br>\n",
        "```changing: self.keras_model.metrics_tensors.append(loss)\n",
        "to: self.keras_model.add_metric(loss, name)````\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ygB8USbgMicl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WORKING_DIR = '/content/gdrive/My Drive/Kaggle/'\n",
        "LOGS_DIR = os.path.join(WORKING_DIR, \"logs\")\n",
        "MASK_RCNN_DIR = os.path.join(WORKING_DIR, 'Mask_RCNN-master')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "daQ_e-MLMicp",
        "colab_type": "code",
        "outputId": "4b4eb199-0705-495f-b39e-05182b5ed060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "# !git clone https://www.github.com/matterport/Mask_RCNN.git \n",
        "# results in Commit Error (too many nested subdirectories)\n",
        "\n",
        "\"\"\" Credit to Simon Walker, whose method helped me to \n",
        "    circumvent the commit error. Check out his kernel at \n",
        "    https://www.kaggle.com/srwalker101/mask-rcnn-model\n",
        "    change to my version\n",
        "\"\"\"\n",
        "!pip install git+https://github.com/Ut0pi4/Mask_RCNN_2"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Ut0pi4/Mask_RCNN_2\n",
            "  Cloning https://github.com/Ut0pi4/Mask_RCNN_2 to /tmp/pip-req-build-pp38l5jp\n",
            "  Running command git clone -q https://github.com/Ut0pi4/Mask_RCNN_2 /tmp/pip-req-build-pp38l5jp\n",
            "Requirement already satisfied (use --upgrade to upgrade): mask-rcnn==2.1 from git+https://github.com/Ut0pi4/Mask_RCNN_2 in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: mask-rcnn\n",
            "  Building wheel for mask-rcnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mask-rcnn: filename=mask_rcnn-2.1-cp36-none-any.whl size=57044 sha256=81202c0ae2cb612c34cbcb504a73816de70732662567d8f74baf3bb52fa77ec8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-09msr57p/wheels/ef/a9/cf/83358ab824e416a8ad95b4a70fc81f562016dbb741ae0b86f4\n",
            "Successfully built mask-rcnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VVKbv4zhMict",
        "colab_type": "code",
        "outputId": "21f8696c-7eb5-4e38-b15f-38c30fbcf968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from mrcnn.utils import Dataset\n",
        "from mrcnn.config import Config\n",
        "from mrcnn.model import MaskRCNN"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYQSmd7SMicy",
        "colab_type": "text"
      },
      "source": [
        "## Configuring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ifx6qKJQMicz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SeverstalConfig(Config):\n",
        "\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"severstal\"\n",
        "\n",
        "    # We use a GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "    IMAGES_PER_GPU = 2\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 4  # background + steel defects\n",
        "\n",
        "    # Number of training steps per epoch\n",
        "    STEPS_PER_EPOCH = 100\n",
        "\n",
        "    # Skip detections with < 90% confidence\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n",
        "    \n",
        "    # Discard inferior model weights\n",
        "    SAVE_BEST_ONLY = True\n",
        "\n",
        "    # BATCH_SIZE = 1\n",
        "    \n",
        "# instantiating \n",
        "severstal_config = SeverstalConfig()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5w44fJkIMic4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# super class can be found here:\n",
        "# https://github.com/matterport/Mask_RCNN/blob/v2.1/utils.py\n",
        "\n",
        "class SeverstalDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, dataframe):\n",
        "        \n",
        "        # https://rhettinger.wordpress.com/2011/05/26/super-considered-super/\n",
        "        super().__init__(self)\n",
        "        \n",
        "        # needs to be in the format of our squashed df, \n",
        "        # i.e. image id and list of rle plus their respective label on a single row\n",
        "        self.dataframe = dataframe\n",
        "        \n",
        "    def load_dataset(self, subset='train'):\n",
        "        \"\"\" takes:\n",
        "                - pandas df containing \n",
        "                    1) file names of our images \n",
        "                       (which we will append to the directory to find our images)\n",
        "                    2) a list of rle for each image \n",
        "                       (which will be fed to our build_mask() \n",
        "                       function we also used in the eda section)         \n",
        "            does:\n",
        "                adds images to the dataset with the utils.Dataset's add_image() metho\n",
        "        \"\"\"\n",
        "        \n",
        "        # input hygiene\n",
        "        assert subset in ['train', 'test'], f'\"{subset}\" is not a valid value.'\n",
        "        img_folder = img_train_folder if subset=='train' else img_test_folder\n",
        "        \n",
        "        # add our four classes\n",
        "        for i in range(1,5):\n",
        "            self.add_class(source='', class_id=i, class_name=f'defect_{i}')\n",
        "        \n",
        "        # add the image to our utils.Dataset class\n",
        "        for index, row in self.dataframe.iterrows():\n",
        "            file_name = row.ImageId\n",
        "            file_path = f'{img_folder}/{file_name}'\n",
        "            \n",
        "            assert os.path.isfile(file_path), 'File doesn\\'t exist.'\n",
        "            self.add_image(source='', \n",
        "                           image_id=file_name, \n",
        "                           path=file_path)\n",
        "    \n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"As found in: \n",
        "            https://github.com/matterport/Mask_RCNN/blob/master/samples/coco/coco.py\n",
        "        \n",
        "        Load instance masks for the given image\n",
        "        \n",
        "        This function converts the different mask format to one format\n",
        "        in the form of a bitmap [height, width, instances]\n",
        "        \n",
        "        Returns:\n",
        "            - masks    : A bool array of shape [height, width, instance count] with\n",
        "                         one mask per instance\n",
        "            - class_ids: a 1D array of class IDs of the instance masks\n",
        "        \"\"\"\n",
        "        \n",
        "        # find the image in the dataframe\n",
        "        row = self.dataframe.iloc[image_id]\n",
        "        \n",
        "        # extract function arguments\n",
        "        rle = row['EncodedPixels']\n",
        "        labels = row['ClassId']\n",
        "        \n",
        "        # create our numpy array mask\n",
        "        mask = build_mask(encodings=rle, labels=labels)\n",
        "        \n",
        "        # we're actually doing semantic segmentation, so our second return value is a bit awkward\n",
        "        # we have one layer per class, rather than per instance... so it will always just be \n",
        "        # 1, 2, 3, 4. See the section on Data Shapes for the Labels.\n",
        "        return mask.astype(np.bool), np.array([1, 2, 3, 4], dtype=np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWJut5FgMic9",
        "colab_type": "text"
      },
      "source": [
        "## Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bYpEt-BBMic-",
        "colab_type": "code",
        "outputId": "66a70a49-8958-40ca-d430-43bed66df93b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "squashed"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageId</th>\n",
              "      <th>EncodedPixels</th>\n",
              "      <th>ClassId</th>\n",
              "      <th>Distinct Defect Types</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0002cc93b.jpg</td>\n",
              "      <td>[29102 12 29346 24 29602 24 29858 24 30114 24 ...</td>\n",
              "      <td>[1]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0007a71bf.jpg</td>\n",
              "      <td>[18661 28 18863 82 19091 110 19347 110 19603 1...</td>\n",
              "      <td>[3]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000a4bcdd.jpg</td>\n",
              "      <td>[37607 3 37858 8 38108 14 38359 20 38610 25 38...</td>\n",
              "      <td>[1]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000f6bf48.jpg</td>\n",
              "      <td>[131973 1 132228 4 132483 6 132738 8 132993 11...</td>\n",
              "      <td>[4]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0014fce06.jpg</td>\n",
              "      <td>[229501 11 229741 33 229981 55 230221 77 23046...</td>\n",
              "      <td>[3]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6661</th>\n",
              "      <td>ffcf72ecf.jpg</td>\n",
              "      <td>[121911 34 122167 101 122422 169 122678 203 12...</td>\n",
              "      <td>[3]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6662</th>\n",
              "      <td>fff02e9c5.jpg</td>\n",
              "      <td>[207523 3 207777 9 208030 15 208283 22 208537 ...</td>\n",
              "      <td>[3]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6663</th>\n",
              "      <td>fffe98443.jpg</td>\n",
              "      <td>[105929 5 106177 14 106424 24 106672 33 106923...</td>\n",
              "      <td>[3]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6664</th>\n",
              "      <td>ffff4eaa8.jpg</td>\n",
              "      <td>[16899 7 17155 20 17411 34 17667 47 17923 60 1...</td>\n",
              "      <td>[3]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6665</th>\n",
              "      <td>ffffd67df.jpg</td>\n",
              "      <td>[30931 43 31103 127 31275 211 31489 253 31745 ...</td>\n",
              "      <td>[3]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6666 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            ImageId  ... Distinct Defect Types\n",
              "0     0002cc93b.jpg  ...                     1\n",
              "1     0007a71bf.jpg  ...                     1\n",
              "2     000a4bcdd.jpg  ...                     1\n",
              "3     000f6bf48.jpg  ...                     1\n",
              "4     0014fce06.jpg  ...                     1\n",
              "...             ...  ...                   ...\n",
              "6661  ffcf72ecf.jpg  ...                     1\n",
              "6662  fff02e9c5.jpg  ...                     1\n",
              "6663  fffe98443.jpg  ...                     1\n",
              "6664  ffff4eaa8.jpg  ...                     1\n",
              "6665  ffffd67df.jpg  ...                     1\n",
              "\n",
              "[6666 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rMUg_cbIMidB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# stratified split to maintain the same class balance in both sets\n",
        "train, validate = train_test_split(squashed, test_size=0.2, random_state=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzrRiQFhMidF",
        "colab_type": "text"
      },
      "source": [
        "We now have a validation set that has the same class distribution as the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "t233wARpMidF",
        "colab_type": "code",
        "outputId": "99e4c47c-36ee-480c-be8c-042788e4ee66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "print(train['ClassId'].astype(str).value_counts(normalize=True))\n",
        "print('')\n",
        "print(validate['ClassId'].astype(str).value_counts(normalize=True))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3]          0.716992\n",
            "[1]          0.112716\n",
            "[4]          0.076144\n",
            "[3, 4]       0.041448\n",
            "[2]          0.031133\n",
            "[1, 3]       0.012566\n",
            "[1, 2]       0.006189\n",
            "[2, 3]       0.002251\n",
            "[1, 2, 3]    0.000375\n",
            "[2, 4]       0.000188\n",
            "Name: ClassId, dtype: float64\n",
            "\n",
            "[3]       0.701649\n",
            "[1]       0.125937\n",
            "[4]       0.082459\n",
            "[3, 4]    0.047226\n",
            "[2]       0.021739\n",
            "[1, 3]    0.017991\n",
            "[1, 2]    0.001499\n",
            "[2, 3]    0.001499\n",
            "Name: ClassId, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3cAKOyRMMidI",
        "colab_type": "code",
        "outputId": "d123b5b2-8ec7-424b-d31d-3062856acacf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# instantiating training set\n",
        "dataset_train = SeverstalDataset(dataframe=train)\n",
        "dataset_train.load_dataset()\n",
        "dataset_train.prepare()\n",
        "\n",
        "# instantiating validation set\n",
        "dataset_validate = SeverstalDataset(dataframe=validate)\n",
        "dataset_validate.load_dataset()\n",
        "dataset_validate.prepare()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.08 s, sys: 441 ms, total: 2.53 s\n",
            "Wall time: 10.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gg-vE9CMidM",
        "colab_type": "text"
      },
      "source": [
        "## Pre-Trained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "d28XATXOMidN",
        "colab_type": "code",
        "outputId": "7bca6d0f-78cf-4a2e-b7bd-838cb5723110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!curl -LO https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   630  100   630    0     0   2530      0 --:--:-- --:--:-- --:--:--  2530\n",
            "100  245M  100  245M    0     0  82.2M      0  0:00:02  0:00:02 --:--:--  101M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EfS-C57MidR",
        "colab_type": "text"
      },
      "source": [
        "## Instantiating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xKnbtQZ2MidR",
        "colab_type": "code",
        "outputId": "0ade1a8f-599c-4a0c-f057-72af612ea1e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "\n",
        "# configuration\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# session stuff\n",
        "session = tf.Session(config=config)\n",
        "session.run(tf.global_variables_initializer())\n",
        "session.run(tf.local_variables_initializer())\n",
        "\n",
        "# initialiazing model\n",
        "model = MaskRCNN(mode='training', config=severstal_config, model_dir='modeldir')\n",
        "\n",
        "# we will retrain starting with the coco weights\n",
        "model.load_weights('mask_rcnn_coco.h5', \n",
        "                   by_name=True, \n",
        "                   exclude=['mrcnn_bbox_fc',\n",
        "                            'mrcnn_class_logits', \n",
        "                            'mrcnn_mask',\n",
        "                            'mrcnn_bbox'])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mrcnn/model.py:601: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rnNdgpaMidU",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"7\"></a> <br>\n",
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dhjr7a80MidV",
        "colab_type": "code",
        "outputId": "1ea420a2-2da0-4b08-bfd2-7fb25fafcb84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        }
      },
      "source": [
        "%%time \n",
        "\n",
        "# ignore UserWarnongs\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# training at last\n",
        "model.train(dataset_train,\n",
        "            dataset_validate,\n",
        "            epochs=1,\n",
        "            layers='heads',\n",
        "            learning_rate=severstal_config.LEARNING_RATE)\n",
        "\n",
        "history = model.keras_model.history.history"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: modeldir/severstal20200523T1012/mask_rcnn_severstal_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mrcnn/model.py:2364: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
            "\n",
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... An op outside of the function building code is being passed\n",
            "a \"Graph\" tensor. It is possible to have Graph tensors\n",
            "leak out of the function building context by including a\n",
            "tf.init_scope in your function building code.\n",
            "For example, the following function will fail:\n",
            "  @tf.function\n",
            "  def has_init_scope():\n",
            "    my_constant = tf.constant(1.)\n",
            "    with tf.init_scope():\n",
            "      added = my_constant * 2\n",
            "The graph tensor has name: anchors/Variable:0\n",
            "Epoch 1/1\n",
            "100/100 [==============================] - 437s 4s/step - loss: 13.3388 - rpn_class_loss: 1.0921 - rpn_bbox_loss: 10.3811 - mrcnn_class_loss: 0.0165 - mrcnn_bbox_loss: 1.5372 - mrcnn_mask_loss: 0.3119 - val_loss: 12.7711 - val_rpn_class_loss: 0.3713 - val_rpn_bbox_loss: 8.4881 - val_mrcnn_class_loss: 0.0033 - val_mrcnn_bbox_loss: 0.4555 - val_mrcnn_mask_loss: 0.0680\n",
            "CPU times: user 4min, sys: 31.1 s, total: 4min 31s\n",
            "Wall time: 8min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnNioqc64ey4",
        "colab_type": "code",
        "outputId": "2184c686-29b2-4441-c47e-2f915dda2fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "history"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [13.33883167743683],\n",
              " 'mrcnn_bbox_loss': [1.5372369],\n",
              " 'mrcnn_class_loss': [0.016511273],\n",
              " 'mrcnn_mask_loss': [0.3119119],\n",
              " 'rpn_bbox_loss': [10.381086],\n",
              " 'rpn_class_loss': [1.0920848],\n",
              " 'val_loss': [12.77108097076416],\n",
              " 'val_mrcnn_bbox_loss': [0.45552998781204224],\n",
              " 'val_mrcnn_class_loss': [0.0033481984864920378],\n",
              " 'val_mrcnn_mask_loss': [0.06803055852651596],\n",
              " 'val_rpn_bbox_loss': [8.488093376159668],\n",
              " 'val_rpn_class_loss': [0.3712553381919861]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C4WyAxaMidY",
        "colab_type": "text"
      },
      "source": [
        "# To-Do\n",
        "* Split kernels into training & inference\n",
        "* \"Squashed\" DataFrame for inference on the competition set\n",
        "* Improving the model\n",
        "\n",
        "Have fun!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "339WeGUL732_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "f24fde3b-1b3c-4347-d926-7654b414d88e"
      },
      "source": [
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# session stuff\n",
        "session = tf.Session(config=config)\n",
        "session.run(tf.global_variables_initializer())\n",
        "session.run(tf.local_variables_initializer())\n",
        "\n",
        "\n",
        "infer = MaskRCNN(mode='inference', config=severstal_config, model_dir='modeldir')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mrcnn/model.py:773: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XqJx5L-aN9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset setup\n",
        "class TestDataset(Dataset):\n",
        "    '''Dataset for test prediction'''\n",
        "    def __init__(self, root, df, mean, std):\n",
        "        self.root = root\n",
        "        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
        "        self.fnames = df['ImageId'].unique().tolist()\n",
        "        self.num_samples = len(self.fnames)\n",
        "        self.transform = Compose(\n",
        "            [\n",
        "                Normalize(mean=mean, std=std, p=1),\n",
        "                ToTensor(),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.fnames[idx]\n",
        "        path = os.path.join(self.root, fname)\n",
        "        image = cv2.imread(path)\n",
        "        images = self.transform(image=image)[\"image\"]\n",
        "        return fname, images\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnU4WTJPsSJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pdb import set_trace\n",
        "test_image_path = os.path.join(img_test_folder,'*g')\n",
        "files = glob.glob(test_image_path)\n",
        "test_data = []\n",
        "test_image_name = []\n",
        "i=0\n",
        "for f in files:\n",
        "    img = cv.imread(f)\n",
        "    test_data.append(img)\n",
        "    # set_trace()\n",
        "    test_image_name.append(f.split(\"/\")[-1])\n",
        "    if i==0:\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "538nVVr58WVU",
        "colab_type": "code",
        "outputId": "b5cee1fd-4974-49bc-9c9a-0a57cb110c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "results = infer.detect(test_data, test_image_name)\n",
        "classes = np.zeros((len(results)))\n",
        "masks = []\n",
        "image_ids = []\n",
        "rles = []\n",
        "for j, result in enumerate(results):\n",
        "    classes[j] = result.class_ids\n",
        "    image_ids.append(result.image_id)\n",
        "    rles.append([])\n",
        "    for mask in result.masks:\n",
        "        rles[j].append(mask_to_rle(mask))\n",
        "    masks.append(result.masks)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-1c644ab0f12f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/mrcnn/model.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, images, images_name, verbose)\u001b[0m\n\u001b[1;32m   2531\u001b[0m         \u001b[0;31m# Run object detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrcnn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2533\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmolded_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_metas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2534\u001b[0m         \u001b[0;31m# Process detections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2535\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3632\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: slice index 1 of dimension 0 out of bounds.\n\t [[{{node ROI_1/strided_slice_12}}]]\n\t [[mrcnn_detection/map/while/body/_1331/GatherV2_3/_7863]]\n  (1) Invalid argument: slice index 1 of dimension 0 out of bounds.\n\t [[{{node ROI_1/strided_slice_12}}]]\n0 successful operations.\n0 derived errors ignored."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SllR0vrts3Fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGvrqsR1MidZ",
        "colab_type": "text"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "X8cGgEOoMidZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # reading in the testing set\n",
        "# data = pd.read_csv('/content/gdrive/My Drive/Kaggle/severstal-steel-defect-detection/sample_submission.csv')\n",
        "\n",
        "# # isolating the file name and class\n",
        "# data['ImageId'] = data.ImageId\n",
        "# data['ClassId'] = data.ClassId\n",
        "# # data['ImageId'], data['ClassId'] = data.ImageId_ClassId.str.split('_', n=1).str\n",
        "# data['ClassId'] = data['ClassId'].astype(np.uint8)\n",
        "\n",
        "# # storing a list of images without defects for later use and testing\n",
        "# no_defects = data[data['EncodedPixels'].isna()] \\\n",
        "#                 [['ImageId']] \\\n",
        "#                 .drop_duplicates()\n",
        "\n",
        "# # adding the columns so we can append (a sample of) the dataset if need be, later\n",
        "# no_defects['EncodedPixels'] = ''\n",
        "# no_defects['ClassId'] = np.empty((len(no_defects), 0)).tolist()\n",
        "# no_defects['Distinct Defect Types'] = 0\n",
        "# no_defects.reset_index(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1CZ-lt3mMidc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # keep only the images with labels\n",
        "# test = data.dropna(subset=['EncodedPixels'], axis='rows', inplace=True)\n",
        "\n",
        "# # squash multiple rows per image into a list\n",
        "# test = data[['ImageId', 'EncodedPixels', 'ClassId']] \\\n",
        "#             .groupby('ImageId', as_index=False) \\\n",
        "#             .agg(list) \\\n",
        "\n",
        "# # count the amount of class labels per image\n",
        "# test['Distinct Defect Types'] = test.ClassId.apply(lambda x: len(x))\n",
        "\n",
        "# # display first ten to show new structure\n",
        "# test.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "00EoSmv5Midf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(f\"\"\"The testing set now consists of {len(test):,} distinct images,\n",
        "# for a total of {test[\"Distinct Defect Types\"].sum():,} labeled mask instances.\n",
        "\n",
        "# Furthermore, we have kept a backup of {len(no_defects):,} images witout defects,\n",
        "# in case our model starts producing a lot of false positives and needs more training\n",
        "# on a background class.\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EhKnpyW9Midi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiating testing set\n",
        "# dataset_test = SeverstalDataset(dataframe=test)\n",
        "# dataset_test.load_dataset(\"test\")\n",
        "# dataset_test.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1dsnIxHfMidl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_img_lst = []\n",
        "# for i in range(dataset_test.num_images):\n",
        "    # test_img_lst.append(dataset_test.load_image(dataset_test._image_ids[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1WeOt7UjA_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_img_lst "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2Q3AevomMido",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# results = model.detect(test_img_lst)\n",
        "# classes = np.zeros((len(results)))\n",
        "# for j, result in enumerate(results):\n",
        "#     classes[j] = result.class_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6k3yVvEhMids",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}